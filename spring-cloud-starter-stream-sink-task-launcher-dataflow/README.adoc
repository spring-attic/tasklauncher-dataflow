//tag::ref-doc[]
= TaskLauncher Data Flow Sink

This application launches a registered task application using the Data Flow Server https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#api-guide-resources-task-executions-launching[REST API].

== Input

Launch request args including:

* the task name (required and registered as a task with the target Data Flow Server)
* deployment properties (key value pairs, optional).
* program arguments for the task (a list, optional).

=== Headers:

* `Content-Type: application/json`

=== Payload:

A JSON document:

[source,json]
----
{
  "name":"foo",
  "deploymentProps": {"key1":"val1","key2":"val2"},
  "args":["--debug", "--foo", "bar"]
}
----

minimally,

[source,json]
----
{"name":"foo"}
----

== Output

N/A (launches task on the SCDF server's task platform).

=== Options

The **$$tasklauncher-dataflow$$** $$sink$$ supports the following configuration properties:

//tag::configuration-properties[]
$$dataflow-server-access-token$$:: $$OAuth2 Access Token.$$ *($$String$$, default: `$$<none>$$`)*
$$oauth2-client-credentials-client-id$$:: $$The OAuth2 Client Id (Used for the client credentials grant).$$ *($$String$$, default: `$$<none>$$`)*
$$oauth2-client-credentials-client-secret$$:: $$The OAuth2 Client Secret (Used for the client credentials grant).$$ *($$String$$, default: `$$<none>$$`)*
$$oauth2-client-credentials-scopes$$:: $$OAuth2 Authorization scopes (Used for the client credentials grant).$$ *($$Set<String>$$, default: `$$<none>$$`)*
$$oauth2-client-credentials-token-uri$$:: $$Token URI for the OAuth2 provider (Used for the client credentials grant).$$ *($$String$$, default: `$$<none>$$`)*
$$platform-name$$:: $$The Spring Cloud Data Flow platform to use for launching tasks.$$ *($$String$$, default: `$$default$$`)*
$$spring.cloud.dataflow.client.authentication.basic.password$$:: $$The login password.$$ *($$String$$, default: `$$<none>$$`)*
$$spring.cloud.dataflow.client.authentication.basic.username$$:: $$The login username.$$ *($$String$$, default: `$$<none>$$`)*
$$spring.cloud.dataflow.client.enable-dsl$$:: $$Enable Data Flow DSL access.$$ *($$Boolean$$, default: `$$false$$`)*
$$spring.cloud.dataflow.client.server-uri$$:: $$The Data Flow server URI.$$ *($$String$$, default: `$$http://localhost:9393$$`)*
$$spring.cloud.dataflow.client.skip-ssl-validation$$:: $$Skip Ssl validation.$$ *($$Boolean$$, default: `$$true$$`)*
$$trigger.initial-delay$$:: $$The initial delay in milliseconds.$$ *($$Integer$$, default: `$$1000$$`)*
$$trigger.max-period$$:: $$The maximum polling period in milliseconds. Will be set to period if period > maxPeriod.$$ *($$Integer$$, default: `$$30000$$`)*
$$trigger.period$$:: $$The polling period in milliseconds.$$ *($$Integer$$, default: `$$1000$$`)*
//end::configuration-properties[]

== Using the TaskLauncher
Th Dataflow tasklauncher is a sink that consumes  `LaunchRequest` messages, as described above, and launches a task using the configured Spring Cloud Data Flow server (given by `--dataflow.uri`).
The task launcher periodically polls its input for launch requests but will pause when the platform has reached it's concurrent task execution limit, given by `spring.cloud.dataflow.task.platform.<platform-type>.accounts[<account-name>].maximum-concurrent-tasks`.
This prevents the SCDF deployer's deployment platform from exhausting its resources under heavy task load.
The poller is scheduled using a `DynamicPeriodicTrigger`. By default the polling rate is 1 second, but may be configured to any duration. When paused, or if there are no launch requests, the trigger period will increase, applying exponential backoff, up to a configured maximum (30 seconds by default).

NOTE: This version of the Dataflow tasklauncher requires SCDF version 2.0.2 or higher.

The SCDF 2.x server may be configured to launch tasks on multiple platforms.
Each task launcher instance is configured for a single platform, given by the `platformName` property (`default` if not specified).
This limitation is enforced because if the server has multiple task platforms configured, it may be the case that some of its task platforms are at the limit and some are not.
In this situation, we could only consume the next launch request if we know for which task platform it is targeted.
For this reason, if the SCDF server is configured for multiple task platforms (or a single non-default platform), we assume that all launch requests are targeted for that platform.
The tasklauncher will set the required deployment property `spring.cloud.dataflow.task.platformName` if the request does not provide it.

NOTE: If the request includes the deployment property `spring.cloud.dataflow.task.platformName`, and the value is not the same as the tasklauncher's `platformName`, the request will not be submitted and an exception will be thrown.

To launch tasks on multiple platforms, you must configure a task launcher instance per platform and use a https://github.com/spring-cloud-stream-app-starters/router/tree/master/spring-cloud-starter-stream-sink-router[router sink], or https://docs.spring.io/spring-cloud-stream/docs/current/reference/htmlsingle/#partitioning[partitioning strategy], to route requests to the correct instance.

NOTE: When the poller is paused it puts pressure
 on the message broker so some tuning will be necessary in extreme cases to balance resource utilization.

== Build

[source,bash]
----
$ ./mvnw clean install -PgenerateApps
$ cd apps
----

You can find the corresponding binder based projects here. You can then cd into one one of the folders and
build it:

[source,bash]
----
$ ./mvnw clean package
----

=== Examples

Register a task app and create a task, the
https://github.com/spring-cloud/spring-cloud-task/blob/master/spring-cloud-task-samples/timestamp[timestamp sample]
provides a simple demonstration.

[source,bash]
----
dataflow:>app register --name timestamp --type task --uri ...
dataflow:>stream create http | task-launcher-dataflow-sink --deploy
----

Send a launch request,

[source,bash]
----
$curl http://localhost:<port> -H"Content-Type:application/json" -d '{"name":"timestamp"}'
----

[source,bash]
----
dataflow:>task execution list
╔═════════╤══╤════════════════════════════╤════════════════════════════╤═════════╗
║Task Name│ID│         Start Time         │          End Time          │Exit Code║
╠═════════╪══╪════════════════════════════╪════════════════════════════╪═════════╣
║timestamp│1 │Fri Aug 10 08:48:05 EDT 2018│Fri Aug 10 08:48:05 EDT 2018│0        ║
╚═════════╧══╧════════════════════════════╧════════════════════════════╧═════════╝
----

//end::ref-doc[]
